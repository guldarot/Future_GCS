{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class 3: Model Deployment and Ethical Considerations\n",
    "\n",
    "## Welcome to Week 10, Class 3!\n",
    "In this notebook, weâ€™ll learn how to **deploy** an AI model so it can be used in real-world applications, and weâ€™ll discuss **ethical considerations** in AI, such as bias and fairness. Youâ€™ll save and load a model, create a simple Flask API to serve predictions, and reflect on ethical challenges.\n",
    "\n",
    "**Objectives**:\n",
    "- Save and load trained models using pickle.\n",
    "- Build a Flask API to serve model predictions.\n",
    "- Understand ethical issues in AI, including bias, fairness, and transparency.\n",
    "- Discuss ethics in the context of your capstone project.\n",
    "\n",
    "**Letâ€™s get started!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Why Deploy Models?\n",
    "Training a model is only half the battleâ€”deploying it makes it useful. Deployment means making a model accessible, e.g., via:\n",
    "- A web app (like a sentiment analyzer).\n",
    "- A mobile app.\n",
    "- An internal tool for a company.\n",
    "\n",
    "Weâ€™ll use **Flask**, a lightweight Python framework, to create a simple API that takes text input and returns predictions.\n",
    "\n",
    "**Discussion Question**: What are some real-world apps where deployed AI models are used?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup\n",
    "Letâ€™s install and import the required libraries. Run the cell below to set up the environment.\n",
    "\n",
    "**Note**: Flask apps are typically run locally, not in Jupyter. Weâ€™ll write the Flask code here but test it in a separate `.py` file later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install libraries (uncomment if needed)\n",
    "# !pip install numpy pandas scikit-learn flask joblib nltk\n",
    "\n",
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filter_warnings('ignore')\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Saving and Loading Models\n",
    "Once a model is trained, we save it to avoid retraining. Weâ€™ll use **joblib** (similar to pickle) to save a sentiment analysis model.\n",
    "\n",
    "Letâ€™s train a simple model (like Class 1â€™s) and save it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Train and Save a Model\n",
    "Weâ€™ll use a toy dataset for sentiment analysis and save the trained model and vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toy dataset\n",
    "data = {\n",
    "    \"review\": [\n",
    "        \"I loved the movie it was great\",\n",
    "        \"Terrible film so boring\",\n",
    "        \"Amazing story and acting\",\n",
    "        \"I hated this movie awful\",\n",
    "        \"Really enjoyed the plot\",\n",
    "        \"Worst movie ever\"\n",
    "    ],\n",
    "    \"sentiment\": [\"positive\", \"negative\", \"positive\", \"negative\", \"positive\", \"negative\"]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Preprocessing function\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Apply preprocessing\n",
    "df[\"clean_review\"] = df[\"review\"].apply(preprocess_text)\n",
    "\n",
    "# Create BoW vectors\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(df[\"clean_review\"])\n",
    "y = df[\"sentiment\"]\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Save model and vectorizer\n",
    "joblib.dump(model, \"sentiment_model.pkl\")\n",
    "joblib.dump(vectorizer, \"vectorizer.pkl\")\n",
    "\n",
    "print(\"Model and vectorizer saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Load and Test the Model\n",
    "Letâ€™s load the saved model and make a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and vectorizer\n",
    "loaded_model = joblib.load(\"sentiment_model.pkl\")\n",
    "loaded_vectorizer = joblib.load(\"vectorizer.pkl\")\n",
    "\n",
    "# Test a new review\n",
    "new_review = \"This movie was fantastic\"\n",
    "clean_review = preprocess_text(new_review)\n",
    "new_vector = loaded_vectorizer.transform([clean_review])\n",
    "prediction = loaded_model.predict(new_vector)\n",
    "\n",
    "print(f\"Review: {new_review}\\nPredicted sentiment: {prediction[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Turn**: Test the loaded model on a review of your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "your_review = \"Your review here\"  # Write your own review\n",
    "clean_your_review = preprocess_text(your_review)\n",
    "your_vector = loaded_vectorizer.transform([clean_your_review])\n",
    "your_prediction = loaded_model.predict(your_vector)\n",
    "\n",
    "print(f\"Your review: {your_review}\\nPredicted sentiment: {your_prediction[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Creating a Flask API\n",
    "An **API** lets users interact with your model over the web. Weâ€™ll create a Flask app that:\n",
    "- Accepts a text review (via a POST request).\n",
    "- Returns the predicted sentiment.\n",
    "\n",
    "**Note**: Weâ€™ll write the Flask code here, but youâ€™ll need to run it in a separate `.py` file (e.g., `app.py`) outside Jupyter.\n",
    "\n",
    "Below is the Flask app code. Copy it into a file named `app.py` in the same folder as `sentiment_model.pkl` and `vectorizer.pkl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a template for app.py (donâ€™t run in Jupyter)\n",
    "print(\"\"\"\n",
    "from flask import Flask, request, jsonify\n",
    "import joblib\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load model and vectorizer\n",
    "model = joblib.load(\"sentiment_model.pkl\")\n",
    "vectorizer = joblib.load(\"vectorizer.pkl\")\n",
    "\n",
    "# NLTK setup\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    data = request.get_json()\n",
    "    if 'review' not in data:\n",
    "        return jsonify({'error': 'No review provided'}), 400\n",
    "    review = data['review']\n",
    "    clean_review = preprocess_text(review)\n",
    "    vector = vectorizer.transform([clean_review])\n",
    "    prediction = model.predict(vector)[0]\n",
    "    return jsonify({'review': review, 'sentiment': prediction})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, host='0.0.0.0', port=5000)\n",
    "\"\"\")\n",
    "\n",
    "print(\"Copy the above code into 'app.py'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 How to Run and Test the API\n",
    "1. Save the code above as `app.py`.\n",
    "2. Ensure `sentiment_model.pkl` and `vectorizer.pkl` are in the same folder.\n",
    "3. Open a terminal, navigate to the folder, and run:\n",
    "   ```bash\n",
    "   python app.py\n",
    "   ```\n",
    "4. The API will run at `http://localhost:5000`.\n",
    "5. Test it using a tool like `curl` or Pythonâ€™s `requests` library (example below).\n",
    "\n",
    "**Test the API** with this code (run in a separate notebook or script):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test API (run this in a separate notebook/script after starting app.py)\n",
    "import requests\n",
    "\n",
    "url = \"http://localhost:5000/predict\"\n",
    "data = {\"review\": \"This movie was amazing\"}\n",
    "\n",
    "try:\n",
    "    response = requests.post(url, json=data)\n",
    "    print(response.json())\n",
    "except:\n",
    "    print(\"Make sure app.py is running!\")\n",
    "\n",
    "# Note: This wonâ€™t work in Jupyter unless app.py is running elsewhere."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Turn**: After setting up `app.py`, test the API with a review of your own. Share the response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Ethical Considerations in AI\n",
    "AI models can have unintended consequences, like **bias**, **unfairness**, or **lack of transparency**. Letâ€™s explore:\n",
    "\n",
    "- **Bias**: Models reflect biases in data. E.g., if reviews are mostly from one group, the model may misjudge othersâ€™ sentiments.\n",
    "- **Fairness**: Ensure models donâ€™t favor certain groups (e.g., biased hiring algorithms).\n",
    "- **Transparency**: Users should know how predictions are made.\n",
    "\n",
    "**Example**: A sentiment model trained on formal reviews might misclassify slang-heavy text (e.g., \"This movie slaps!\" as negative).\n",
    "\n",
    "**Case Study**: The COMPAS algorithm predicted higher recidivism risk for certain groups, raising fairness concerns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Hands-On: Exploring Bias\n",
    "Letâ€™s test our model for potential bias by trying reviews with slang or unusual phrasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test reviews with slang or edge cases\n",
    "test_reviews = [\n",
    "    \"This movie slaps, so dope!\",  # Positive slang\n",
    "    \"Film was mid, nothing special\",  # Neutral slang\n",
    "    \"Not my cup of tea but okay\"   # Ambiguous\n",
    "]\n",
    "\n",
    "for review in test_reviews:\n",
    "    clean_review = preprocess_text(review)\n",
    "    vector = loaded_vectorizer.transform([clean_review])\n",
    "    prediction = loaded_model.predict(vector)[0]\n",
    "    print(f\"Review: {review}\\nPredicted sentiment: {prediction}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Turn**: Write two reviews (e.g., one with slang, one ambiguous) and test them. Do the predictions seem fair?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "your_test_reviews = [\n",
    "    \"Your first review here\",  # Try slang or unusual phrasing\n",
    "    \"Your second review here\"  # Try ambiguous or tricky text\n",
    "]\n",
    "\n",
    "for review in your_test_reviews:\n",
    "    clean_review = preprocess_text(review)\n",
    "    vector = loaded_vectorizer.transform([clean_review])\n",
    "    prediction = loaded_model.predict(vector)[0]\n",
    "    print(f\"Your review: {review}\\nPredicted sentiment: {prediction}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion**:\n",
    "- Did the model misclassify any reviews? Why might that happen?\n",
    "- How could bias in our toy dataset (e.g., formal language) affect predictions?\n",
    "- What ethical concerns might arise in your capstone project?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Wrap-Up\n",
    "Youâ€™ve learned:\n",
    "- How to save and load models with joblib.\n",
    "- How to create a Flask API to serve predictions.\n",
    "- Key ethical issues in AI and how to spot bias.\n",
    "\n",
    "**Homework**:\n",
    "- Read about AI ethics: [AI Bias Examples](https://www.wired.com/story/how-algorithmic-bias-can-impact-your-life/).\n",
    "- Brainstorm ethical considerations for your capstone project (e.g., biased data, fairness).\n",
    "\n",
    "**Deliverables**:\n",
    "- Submit this notebook with completed \"Your Turn\" sections.\n",
    "- Include a screenshot or output of your Flask API test.\n",
    "- Write a short paragraph on one ethical challenge you observed.\n",
    "\n",
    "**Questions?** Reach out to the instructor or discuss with peers.\n",
    "\n",
    "Great job, and see you in Class 4 for capstone project work! ðŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}