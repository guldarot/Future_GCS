{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class 3: File Handling and Real-World Data\n",
    "\n",
    "**Week 4: Intermediate Python and Data Preprocessing**\n",
    "\n",
    "## Objectives\n",
    "- Read and write JSON files for flexible data handling.\n",
    "- Process large CSV files efficiently using chunks.\n",
    "- Begin the mini-project by applying preprocessing steps to a real-world dataset (Titanic).\n",
    "- Understand the importance of file format flexibility in data science workflows.\n",
    "\n",
    "## Datasets\n",
    "- **Titanic dataset** (`titanic.csv`): Contains columns like `PassengerId`, `Pclass`, `Name`, `Sex`, `Age`, `Fare`, `Embarked`, `Survived`. Used for the mini-project.\n",
    "- **Sample JSON** (`sample.json`): A small dataset with passenger-like records (e.g., `id`, `name`, `ticket_cost`).\n",
    "\n",
    "## Instructions\n",
    "- Run the setup cell to load libraries.\n",
    "- Complete the exercises by filling in the code cells.\n",
    "- Use the hints if you're stuck.\n",
    "- Start the mini-project in Exercise 3 and save your progress.\n",
    "- Save your notebook and submit it if required.\n",
    "\n",
    "## Setup\n",
    "Run the cell below to import libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Verify datasets are accessible\n",
    "try:\n",
    "    titanic = pd.read_csv('data/titanic.csv')\n",
    "    print('Titanic dataset loaded successfully.')\n",
    "    print(titanic.head())\n",
    "except FileNotFoundError:\n",
    "    print('Error: titanic.csv not found in data/ folder.')\n",
    "\n",
    "try:\n",
    "    with open('data/sample.json', 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "    print('\\nSample JSON loaded successfully:')\n",
    "    print(json_data[:2])  # Show first two records\n",
    "except FileNotFoundError:\n",
    "    print('Error: sample.json not found in data/ folder.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Reading and Writing JSON\n",
    "\n",
    "**Goal**: Work with JSON files to handle semi-structured data.\n",
    "\n",
    "**Task**:\n",
    "- Read `sample.json` into a pandas DataFrame.\n",
    "- Filter rows where `ticket_cost` is greater than 50.\n",
    "- Save the filtered data as a new JSON file (`filtered.json`).\n",
    "\n",
    "**Steps**:\n",
    "1. Use `json.load()` to read `sample.json` (already done in setup).\n",
    "2. Convert the JSON data to a DataFrame with `pd.DataFrame()`.\n",
    "3. Filter rows using boolean indexing.\n",
    "4. Save the filtered DataFrame to JSON using `to_json()`.\n",
    "\n",
    "**Hint**: Use `orient='records'` in `to_json()` to match the input JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "# Convert JSON data to DataFrame\n",
    "json_df = # YOUR CODE\n",
    "\n",
    "# Filter rows where ticket_cost > 50\n",
    "filtered_df = # YOUR CODE\n",
    "\n",
    "# Save to filtered.json\n",
    "# YOUR CODE\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "print('Filtered DataFrame:')\n",
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution (Instructor Reference)\n",
    "\n",
    "Uncomment and run the cell below to check your work. Try to complete the exercise yourself first!\n",
    "\n",
    "```python\n",
    "# json_df = pd.DataFrame(json_data)\n",
    "# filtered_df = json_df[json_df['ticket_cost'] > 50]\n",
    "# filtered_df.to_json('data/filtered.json', orient='records', lines=True)\n",
    "# print('Filtered DataFrame:')\n",
    "# print(filtered_df)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Advanced CSV Processing\n",
    "\n",
    "**Goal**: Process large CSV files efficiently using chunks.\n",
    "\n",
    "**Task**:\n",
    "- Read `titanic.csv` in chunks of 100 rows.\n",
    "- For each chunk, count the number of passengers by `Pclass`.\n",
    "- Sum the counts across chunks to get the total passengers per class.\n",
    "\n",
    "**Steps**:\n",
    "1. Use `pd.read_csv()` with `chunksize=100` to create a chunk iterator.\n",
    "2. In a loop, use `value_counts()` to count `Pclass` in each chunk.\n",
    "3. Aggregate counts across chunks (e.g., store in a dictionary or Series).\n",
    "4. Display the final counts.\n",
    "\n",
    "**Hint**: Initialize an empty Series or dictionary to accumulate counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "# Initialize a Series to store counts\n",
    "class_counts = pd.Series(dtype=int)\n",
    "\n",
    "# Read titanic.csv in chunks\n",
    "for chunk in # YOUR CODE:\n",
    "    # Count Pclass in this chunk\n",
    "    chunk_counts = # YOUR CODE\n",
    "    # Add to total counts\n",
    "    class_counts = class_counts.add(chunk_counts, fill_value=0)\n",
    "\n",
    "# Display the result\n",
    "print('Total passengers by Pclass:')\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution (Instructor Reference)\n",
    "\n",
    "Uncomment and run the cell below to check your work.\n",
    "\n",
    "```python\n",
    "# class_counts = pd.Series(dtype=int)\n",
    "# for chunk in pd.read_csv('data/titanic.csv', chunksize=100):\n",
    "#     chunk_counts = chunk['Pclass'].value_counts()\n",
    "#     class_counts = class_counts.add(chunk_counts, fill_value=0)\n",
    "# print('Total passengers by Pclass:')\n",
    "# print(class_counts)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Mini-Project Kickoff\n",
    "\n",
    "**Goal**: Start preprocessing the Titanic dataset for the Week 4 mini-project.\n",
    "\n",
    "**Task**:\n",
    "- Load `titanic.csv`.\n",
    "- Handle missing values:\n",
    "  - Fill missing `Age` with the median.\n",
    "  - Fill missing `Embarked` with the mode.\n",
    "- Encode categorical variables:\n",
    "  - One-hot encode `Sex`.\n",
    "  - One-hot encode `Embarked`.\n",
    "- Normalize `Fare` using `MinMaxScaler`.\n",
    "- Save the preprocessed DataFrame to a new CSV (`titanic_preprocessed.csv`).\n",
    "\n",
    "**Steps**:\n",
    "1. Load the dataset (already done in setup).\n",
    "2. Use `fillna()` for missing values.\n",
    "3. Use `pd.get_dummies()` for encoding.\n",
    "4. Use `MinMaxScaler` from scikit-learn for normalization.\n",
    "5. Save with `to_csv()`.\n",
    "\n",
    "**Hint**: Reuse techniques from Classes 1 and 2. Check for missing values with `isna().sum()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Check missing values\n",
    "print('Missing values before:')\n",
    "print(titanic.isna().sum())\n",
    "\n",
    "# Handle missing values\n",
    "# YOUR CODE (Age and Embarked)\n",
    "\n",
    "# Encode categorical variables\n",
    "# YOUR CODE (Sex and Embarked)\n",
    "\n",
    "# Normalize Fare\n",
    "scaler = # YOUR CODE\n",
    "titanic['Fare_normalized'] = # YOUR CODE\n",
    "\n",
    "# Check missing values after\n",
    "print('\\nMissing values after:')\n",
    "print(titanic.isna().sum())\n",
    "\n",
    "# Save to CSV\n",
    "# YOUR CODE\n",
    "\n",
    "# Display the first few rows\n",
    "print('\\nPreprocessed DataFrame:')\n",
    "print(titanic.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution (Instructor Reference)\n",
    "\n",
    "Uncomment and run the cell below to check your work.\n",
    "\n",
    "```python\n",
    "# print('Missing values before:')\n",
    "# print(titanic.isna().sum())\n",
    "# titanic['Age'] = titanic['Age'].fillna(titanic['Age'].median())\n",
    "# titanic['Embarked'] = titanic['Embarked'].fillna(titanic['Embarked'].mode()[0])\n",
    "# titanic = pd.get_dummies(titanic, columns=['Sex', 'Embarked'], drop_first=False)\n",
    "# scaler = MinMaxScaler()\n",
    "# titanic['Fare_normalized'] = scaler.fit_transform(titanic[['Fare']].values.reshape(-1, 1))\n",
    "# print('\\nMissing values after:')\n",
    "# print(titanic.isna().sum())\n",
    "# titanic.to_csv('data/titanic_preprocessed.csv', index=False)\n",
    "# print('\\nPreprocessed DataFrame:')\n",
    "# print(titanic.head())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Challenge\n",
    "\n",
    "**Task**: Convert the preprocessed Titanic DataFrame to JSON and save it as `titanic_preprocessed.json`.\n",
    "- Ensure the JSON format is a list of records (like `sample.json`).\n",
    "- Load the saved JSON back into a DataFrame to verify it matches.\n",
    "\n",
    "**Hint**: Use `to_json(orient='records', lines=True)` and `pd.read_json()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "# Save preprocessed DataFrame to JSON\n",
    "# YOUR CODE\n",
    "\n",
    "# Load JSON back to verify\n",
    "verify_df = # YOUR CODE\n",
    "print('Verified JSON DataFrame:')\n",
    "print(verify_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion Questions\n",
    "1. Why is JSON a popular format for data exchange?\n",
    "2. How does chunked CSV processing help with large datasets?\n",
    "3. What challenges might arise when preprocessing real-world datasets like Titanic?\n",
    "\n",
    "Feel free to jot down your thoughts in a new markdown cell below!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Notes\n",
    "\n",
    "(Add your thoughts here)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}