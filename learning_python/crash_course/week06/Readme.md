Week 6: Supervised Learning Algorithms
Overview
Week 6 introduces students to supervised learning algorithms, focusing on classification tasks. Students will explore key algorithms (logistic regression, k-nearest neighbors, and decision trees), learn how to evaluate models using metrics like accuracy, precision, recall, F1-score, and confusion matrices, and get a basic introduction to hyperparameter tuning via grid search. By the end, students will be able to implement and compare classification models using scikit-learn.

Objective: Equip students with the skills to build, evaluate, and tune supervised learning models for classification problems.

Duration: 4 classes (assuming ~60 minutes each)

Target Audience: Students with basic Python, pandas, and scikit-learn knowledge.

Learning Outcomes
By the end of Week 6, students will be able to:

Differentiate between classification and regression problems.
Implement logistic regression, k-nearest neighbors (KNN), and decision trees using scikit-learn.
Evaluate models using accuracy, precision, recall, F1-score, and confusion matrices.
Perform basic hyperparameter tuning with grid search.
Build and compare multiple classifiers in a mini-project.
Topics Covered
Classification vs. Regression: Understanding categorical vs. continuous outputs.
Algorithms:
Logistic regression: Predicting probabilities for binary outcomes.
K-nearest neighbors (KNN): Distance-based classification.
Decision trees: Rule-based hierarchical splits.
Evaluation Metrics:
Accuracy, precision, recall, F1-score.
Confusion matrix for analyzing model performance.
Hyperparameter Tuning: Introduction to grid search for optimizing model parameters.
Activities:
Exercises: Train and evaluate logistic regression and KNN models.
Mini-project: Build a classifier to predict Iris species and compare algorithms.
Class Structure
The material is divided into four classes for easy teaching and learning:

Class 1: Introduction to Supervised Learning and Logistic Regression
Topics: Supervised learning basics, classification vs. regression, logistic regression.
Activity: Train a logistic regression model on a binary classification dataset (e.g., Iris subset).
Outcome: Understand supervised learning and run a basic model.
Class 2: K-Nearest Neighbors and Decision Trees
Topics: KNN intuition and mechanics, decision trees structure and use cases.
Activity: Train KNN and decision tree models, compare predictions.
Outcome: Implement and contrast multiple algorithms.
Class 3: Evaluation Metrics
Topics: Accuracy, precision, recall, F1-score, confusion matrix.
Activity: Compute metrics for models from Classes 1-2, visualize confusion matrices.
Outcome: Evaluate and interpret model performance.
Class 4: Hyperparameter Tuning and Mini-Project
Topics: Hyperparameters, grid search, end-to-end model comparison.
Activity: Tune a model and complete a mini-project to predict Iris species.
Outcome: Apply all concepts to build and compare classifiers.