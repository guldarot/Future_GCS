{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class 1: Introduction to Supervised Learning and Logistic Regression\n",
    "\n",
    "**Week 6: Supervised Learning Algorithms**\n",
    "\n",
    "## Overview\n",
    "Welcome to Class 1! Today, we'll explore the basics of **supervised learning**, understand the difference between **classification** and **regression**, and dive into **logistic regression** for classification tasks. By the end, you'll train your first logistic regression model using scikit-learn on a simple dataset.\n",
    "\n",
    "## Objectives\n",
    "- Define supervised learning and its role in machine learning.\n",
    "- Differentiate between classification and regression problems.\n",
    "- Understand how logistic regression works for binary classification.\n",
    "- Train and make predictions with a logistic regression model.\n",
    "\n",
    "## Agenda\n",
    "1. What is supervised learning?\n",
    "2. Classification vs. regression\n",
    "3. Introduction to logistic regression\n",
    "4. Hands-on: Train a logistic regression model\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is Supervised Learning?\n",
    "\n",
    "**Supervised learning** is a type of machine learning where we train a model on **labeled data**. This means we have input features (X) and corresponding outputs (y), and the model learns to predict y from X.\n",
    "\n",
    "**Examples**:\n",
    "- Predicting house prices based on size and location (y = price, X = size, location).\n",
    "- Classifying emails as spam or not spam (y = spam/not spam, X = email content).\n",
    "\n",
    "The goal is to learn a function that maps inputs to outputs, then use it to predict on new, unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Classification vs. Regression\n",
    "\n",
    "Supervised learning problems fall into two categories:\n",
    "\n",
    "- **Regression**: Predicting a **continuous** output.\n",
    "  - Example: Predicting someone's house price (e.g., $300,000).\n",
    "  - Output: A number.\n",
    "- **Classification**: Predicting a **categorical** output.\n",
    "  - Example: Predicting if a flower is a specific species (e.g., setosa or versicolor).\n",
    "  - Output: A class label.\n",
    "\n",
    "**Question**: Can you think of one regression and one classification problem from real life? (Pause and discuss!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Introduction to Logistic Regression\n",
    "\n",
    "**Logistic regression** is a classification algorithm (despite the name!) used for **binary classification** (two classes, e.g., yes/no, 0/1).\n",
    "\n",
    "**How it works** (simplified):\n",
    "- Takes input features (e.g., petal length, width).\n",
    "- Computes a weighted sum of features.\n",
    "- Passes it through a **sigmoid function** to output a probability (0 to 1).\n",
    "- Predicts class 1 if probability > 0.5, else class 0.\n",
    "\n",
    "**Example**: Predicting if a flower is *Iris setosa* (class 1) or not (class 0) based on its features.\n",
    "\n",
    "Today, we'll use logistic regression on the Iris dataset to classify two species."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Hands-On: Train a Logistic Regression Model\n",
    "\n",
    "Let's train a logistic regression model on a subset of the Iris dataset to classify two species (*setosa* vs. *versicolor*). We'll use scikit-learn, a powerful Python library for machine learning.\n",
    "\n",
    "**Steps**:\n",
    "1. Load and prepare the Iris dataset.\n",
    "2. Create a binary classification problem (two classes).\n",
    "3. Split data into training and testing sets.\n",
    "4. Train a logistic regression model.\n",
    "5. Make predictions and check results.\n",
    "\n",
    "Follow along with the code below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Load Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Create binary classification: setosa (0) vs. versicolor (1)\n",
    "# We'll exclude class 2 (virginica) for simplicity\n",
    "mask = y < 2  # Select only setosa and versicolor\n",
    "X_binary = X[mask]\n",
    "y_binary = y[mask]\n",
    "\n",
    "# Use only two features for visualization (petal length, petal width)\n",
    "X_binary = X_binary[:, 2:4]  # Columns 2 and 3\n",
    "\n",
    "# Check the data\n",
    "print(\"Feature names:\", iris.feature_names[2:4])\n",
    "print(\"Target names:\", iris.target_names[:2])\n",
    "print(\"Shape of X:\", X_binary.shape)\n",
    "print(\"Shape of y:\", y_binary.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What did we do?**\n",
    "- Loaded the Iris dataset (150 samples, 4 features).\n",
    "- Selected two classes (setosa, versicolor) for binary classification.\n",
    "- Kept only petal length and petal width for simplicity.\n",
    "- Checked the data dimensions (100 samples, 2 features).\n",
    "\n",
    "Now, let's visualize the data to see how the classes look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the data\n",
    "plt.scatter(X_binary[y_binary == 0, 0], X_binary[y_binary == 0, 1], label=\"Setosa\", color=\"blue\")\n",
    "plt.scatter(X_binary[y_binary == 1, 0], X_binary[y_binary == 1, 1], label=\"Versicolor\", color=\"orange\")\n",
    "plt.xlabel(\"Petal Length (cm)\")\n",
    "plt.ylabel(\"Petal Width (cm)\")\n",
    "plt.title(\"Iris: Setosa vs. Versicolor\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: Do the classes look separable? (Hint: Are the blue and orange dots mostly separate?)\n",
    "\n",
    "Next, we'll split the data into **training** (to learn) and **testing** (to evaluate) sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_binary, y_binary, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training set size:\", X_train.shape)\n",
    "print(\"Testing set size:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What’s happening?**\n",
    "- We split the data: 80% for training (80 samples), 20% for testing (20 samples).\n",
    "- `random_state=42` ensures reproducibility.\n",
    "\n",
    "Now, let's train the logistic regression model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the model\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Show predictions\n",
    "print(\"Test set predictions:\", y_pred)\n",
    "print(\"Actual labels:\", y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your turn!**\n",
    "- Compare `y_pred` and `y_test`. How many predictions look correct?\n",
    "- Try predicting on a new sample. Run the cell below and change the values for `petal_length` and `petal_width`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on a new sample\n",
    "new_sample = np.array([[4.0, 1.2]])  # Example: petal length=4.0, petal width=1.2\n",
    "prediction = model.predict(new_sample)\n",
    "print(\"Predicted class:\", iris.target_names[prediction][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion**:\n",
    "- What class did the model predict for the new sample?\n",
    "- Does the prediction make sense based on the scatter plot?\n",
    "\n",
    "Finally, let's visualize the decision boundary to see how the model separates the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize decision boundary\n",
    "x_min, x_max = X_binary[:, 0].min() - 0.5, X_binary[:, 0].max() + 0.5\n",
    "y_min, y_max = X_binary[:, 1].min() - 0.5, X_binary[:, 1].max() + 0.5\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01), np.arange(y_min, y_max, 0.01))\n",
    "Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "plt.contourf(xx, yy, Z, alpha=0.3, cmap=\"coolwarm\")\n",
    "plt.scatter(X_binary[y_binary == 0, 0], X_binary[y_binary == 0, 1], label=\"Setosa\", color=\"blue\")\n",
    "plt.scatter(X_binary[y_binary == 1, 0], X_binary[y_binary == 1, 1], label=\"Versicolor\", color=\"orange\")\n",
    "plt.xlabel(\"Petal Length (cm)\")\n",
    "plt.ylabel(\"Petal Width (cm)\")\n",
    "plt.title(\"Logistic Regression Decision Boundary\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What’s this?**\n",
    "- The shaded areas show the model's decision regions (blue for setosa, red for versicolor).\n",
    "- The line is the **decision boundary** where the model switches predictions.\n",
    "\n",
    "**Question**: Does the boundary make sense? Are most points correctly classified?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap-Up\n",
    "\n",
    "Today, you:\n",
    "- Learned what **supervised learning** is.\n",
    "- Understood the difference between **classification** and **regression**.\n",
    "- Explored **logistic regression** and how it predicts classes.\n",
    "- Trained a model on the Iris dataset and visualized its decisions.\n",
    "\n",
    "**Homework**:\n",
    "- Explore the [scikit-learn documentation for LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) (5-10 min).\n",
    "- Try changing the `new_sample` values above and predict again. What happens?\n",
    "\n",
    "**Next Class**:\n",
    "- We'll explore two more algorithms: k-nearest neighbors (KNN) and decision trees.\n",
    "- Get ready to compare them with logistic regression!\n",
    "\n",
    "Any questions? Feel free to ask!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}