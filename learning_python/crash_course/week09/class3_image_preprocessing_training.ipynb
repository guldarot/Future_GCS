{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class 3: Image Preprocessing and Training CNNs\n",
    "\n",
    "**Week 9: Convolutional Neural Networks (CNNs) and Image Processing**\n",
    "\n",
    "## Objective\n",
    "In this class, we'll master **image preprocessing** techniques and learn how to train **Convolutional Neural Networks (CNNs)** effectively. You'll preprocess the CIFAR-10 dataset and train an improved CNN, building on the basics from Classes 1 and 2.\n",
    "\n",
    "## Agenda\n",
    "1. Why preprocess images?\n",
    "2. Preprocessing techniques: resizing, normalization, data augmentation.\n",
    "3. Training a CNN: loss functions, optimizers, and hyperparameters.\n",
    "4. Exercise: Preprocess data and train a CNN with augmentation.\n",
    "\n",
    "## Setup\n",
    "Ensure you have the required libraries installed:\n",
    "```bash\n",
    "pip install tensorflow numpy matplotlib\n",
    "```\n",
    "\n",
    "Let's dive in!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Why Preprocess Images?\n",
    "\n",
    "CNNs expect consistent, well-prepared input data to train effectively. Image preprocessing addresses challenges like:\n",
    "- **Varying sizes**: Images must have the same dimensions (e.g., 32x32).\n",
    "- **Large pixel values**: Pixels (0-255) can slow training if not scaled.\n",
    "- **Limited data**: Small datasets lead to overfitting.\n",
    "\n",
    "Common preprocessing steps include:\n",
    "- **Resizing**: Standardize image dimensions.\n",
    "- **Normalization**: Scale pixel values (e.g., to [0,1]).\n",
    "- **Data augmentation**: Generate variations (e.g., flips, rotations) to increase dataset diversity.\n",
    "\n",
    "**Question**: How might augmentation help prevent overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Preprocessing Techniques\n",
    "\n",
    "We'll explore three key techniques using CIFAR-10:\n",
    "\n",
    "1. **Resizing**:\n",
    "   - Ensures all images have the same dimensions (e.g., 32x32 for CIFAR-10).\n",
    "   - CIFAR-10 images are already 32x32, so we'll focus on other steps.\n",
    "\n",
    "2. **Normalization**:\n",
    "   - Scales pixel values to a smaller range (e.g., [0,1] or standardized).\n",
    "   - Helps gradients flow better during training.\n",
    "\n",
    "3. **Data Augmentation**:\n",
    "   - Applies random transformations (e.g., flipping, rotating, zooming).\n",
    "   - Increases dataset size artificially, improving generalization.\n",
    "\n",
    "Let's load CIFAR-10 and apply these techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values to [0, 1]\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Define class names\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "# Verify shapes and pixel range\n",
    "print('Training data shape:', x_train.shape)\n",
    "print('Pixel value range:', x_train.min(), 'to', x_train.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation**:\n",
    "- Normalized pixels by dividing by 255 (from 0-255 to 0-1).\n",
    "- CIFAR-10 images are already 32x32, so no resizing is needed here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Data Augmentation\n",
    "\n",
    "We'll use Keras' `ImageDataGenerator` to apply random transformations during training. This creates varied versions of each image, helping the model generalize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Create data generator with augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,      # Randomly rotate up to 15 degrees\n",
    "    width_shift_range=0.1,  # Shift horizontally by up to 10%\n",
    "    height_shift_range=0.1, # Shift vertically by up to 10%\n",
    "    horizontal_flip=True,   # Randomly flip horizontally\n",
    "    fill_mode='nearest'     # Fill new pixels with nearest values\n",
    ")\n",
    "\n",
    "# Fit the generator to training data\n",
    "datagen.fit(x_train)\n",
    "\n",
    "# Visualize augmented images\n",
    "sample_image = x_train[0:1]  # Take one image\n",
    "plt.figure(figsize=(8, 2))\n",
    "for i, aug_image in enumerate(datagen.flow(sample_image, batch_size=1)):\n",
    "    if i >= 4: break\n",
    "    plt.subplot(1, 5, i + 2)\n",
    "    plt.imshow(aug_image[0])\n",
    "    plt.title('Augmented')\n",
    "    plt.axis('off')\n",
    "plt.subplot(1, 5, 1)\n",
    "plt.imshow(sample_image[0])\n",
    "plt.title('Original')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation**:\n",
    "- `ImageDataGenerator`: Applies random transformations on-the-fly during training.\n",
    "- Transformations: rotation, shifts, and flips make the model robust to variations.\n",
    "- Visualized 4 augmented versions of one image to show the effect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Training a CNN\n",
    "\n",
    "We'll build a slightly deeper CNN than in Class 2, with two convolutional layers, and train it with augmentation. Key training components:\n",
    "- **Loss function**: `sparse_categorical_crossentropy` (for integer labels).\n",
    "- **Optimizer**: Adam (adaptive learning rate).\n",
    "- **Hyperparameters**: Epochs (how many passes), batch size (samples per update).\n",
    "\n",
    "Let's define the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Build the CNN\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Display model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation**:\n",
    "- Two `Conv2D` layers (32 and 64 filters) for better feature extraction.\n",
    "- Two `MaxPooling2D` layers to reduce dimensions.\n",
    "- `Dense(64)` adds capacity before the output layer.\n",
    "- `softmax` outputs probabilities for 10 classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, train the model using the augmented data (this may take a few minutes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with augmentation\n",
    "history = model.fit(datagen.flow(x_train, y_train, batch_size=32),\n",
    "                    epochs=5,\n",
    "                    validation_data=(x_test, y_test))\n",
    "\n",
    "# Plot accuracy and loss\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation**:\n",
    "- Trained for 5 epochs with augmented data via `datagen.flow`.\n",
    "- Batch size of 32 balances speed and stability.\n",
    "- Plotted accuracy and loss to assess training progress.\n",
    "\n",
    "**Note**: Validation accuracy should improve compared to Class 2 due to augmentation and deeper architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Evaluating the Model\n",
    "\n",
    "Let's visualize some predictions to see how the model performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test images\n",
    "predictions = model.predict(x_test[:9])\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Display images with predictions\n",
    "plt.figure(figsize=(8, 8))\n",
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(x_test[i])\n",
    "    plt.title(f'Pred: {class_names[predicted_labels[i]]}\\nTrue: {class_names[y_test[i][0]]}')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation**:\n",
    "- Predicted classes for 9 test images.\n",
    "- Compared predictions to true labels to evaluate performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Experiment with Preprocessing and Training\n",
    "\n",
    "Now it's your turn! Complete the tasks below to deepen your understanding.\n",
    "\n",
    "1. **Modify Augmentation**:\n",
    "   - Change the `rotation_range` to 30 and add `zoom_range=0.2` in `ImageDataGenerator`.\n",
    "   - Visualize 4 augmented versions of a new image (e.g., `x_train[1:2]`).\n",
    "\n",
    "2. **Train Without Augmentation**:\n",
    "   - Train the same CNN model without augmentation (use `model.fit(x_train, y_train, ...)`).\n",
    "   - Plot training and validation accuracy.\n",
    "   - Compare validation accuracy to the augmented model.\n",
    "\n",
    "3. **Challenge (Optional)**:\n",
    "   - Increase the batch size to 64 and train the augmented model for 5 epochs.\n",
    "   - Compare training time and validation accuracy to the original (batch size 32).\n",
    "   - What might a larger batch size affect?\n",
    "\n",
    "Write your code in the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: Modify augmentation\n",
    "# Your code here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Task 2: Train without augmentation\n",
    "# Your code here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Task 3 (Optional): Increase batch size to 64\n",
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap-Up\n",
    "\n",
    "In this class, you:\n",
    "- Learned why preprocessing is critical for CNNs.\n",
    "- Applied normalization and data augmentation to CIFAR-10.\n",
    "- Trained a deeper CNN with augmentation and evaluated its performance.\n",
    "- Explored the impact of preprocessing on training.\n",
    "\n",
    "**Homework**:\n",
    "- Research pre-trained models like VGG16 or ResNet for the next class.\n",
    "- Submit your completed notebook if required.\n",
    "\n",
    "**Next Class**: We'll explore transfer learning to classify images efficiently!\n",
    "\n",
    "Questions? Feel free to ask!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}