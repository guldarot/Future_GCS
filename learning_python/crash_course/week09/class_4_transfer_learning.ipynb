{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class 4: Transfer Learning\n",
    "## Overview\n",
    "In this class, we will explore **Transfer Learning**, a powerful technique in deep learning that leverages pre-trained models to solve new tasks efficiently. We will cover:\n",
    "- Using pre-trained models like VGG16 and ResNet.\n",
    "- The difference between **feature extraction** and **fine-tuning**.\n",
    "- Practical application to an image classification task using a real-world dataset.\n",
    "\n",
    "This notebook uses TensorFlow/Keras and assumes you have a basic understanding of neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "Make sure you have the following libraries installed:\n",
    "- TensorFlow\n",
    "- NumPy\n",
    "- Matplotlib\n",
    "- Scikit-learn\n",
    "\n",
    "You can install them using:\n",
    "```bash\n",
    "pip install tensorflow numpy matplotlib scikit-learn\n",
    "```\n",
    "We will also use the **Cats vs Dogs** dataset, which is available through TensorFlow Datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications import VGG16, ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is Transfer Learning?\n",
    "Transfer learning involves taking a model trained on a large, general dataset (e.g., ImageNet) and reusing it for a specific task. This is particularly useful when you have limited data for your task.\n",
    "\n",
    "### Key Concepts:\n",
    "- **Pre-trained Models**: Models like VGG16, ResNet, or InceptionV3 trained on ImageNet (1.4M images, 1000 classes).\n",
    "- **Feature Extraction**: Use the pre-trained model as a fixed feature extractor, only training a new classifier on top.\n",
    "- **Fine-Tuning**: Adjust the weights of the pre-trained model along with training a new classifier for better performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading and Preprocessing the Dataset\n",
    "We will use the **Cats vs Dogs** dataset for binary classification. The images will be resized to match the input size of pre-trained models (224x224 for VGG16/ResNet).\n",
    "\n",
    "Let's load and preprocess the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Cats vs Dogs dataset\n",
    "(ds_train, ds_test), ds_info = tfds.load('cats_vs_dogs', split=['train[:80%]', 'train[80%:]'], \n",
    "                                         with_info=True, as_supervised=True)\n",
    "\n",
    "# Define preprocessing function\n",
    "IMG_SIZE = 224\n",
    "def preprocess(image, label):\n",
    "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "    image = image / 255.0  # Normalize to [0,1]\n",
    "    return image, label\n",
    "\n",
    "# Apply preprocessing\n",
    "BATCH_SIZE = 32\n",
    "ds_train = ds_train.map(preprocess).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.map(preprocess).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Visualize a few samples\n",
    "def show_images(dataset):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for images, labels in dataset.take(1):\n",
    "        for i in range(9):\n",
    "            plt.subplot(3, 3, i + 1)\n",
    "            plt.imshow(images[i])\n",
    "            plt.title('Cat' if labels[i] == 0 else 'Dog')\n",
    "            plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "show_images(ds_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Extraction with VGG16\n",
    "In **feature extraction**, we use a pre-trained model to extract features from the input images and train only a new classifier on top. Here, we'll use VGG16 as the base model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load VGG16 model (without the top layer)\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "# Freeze the base model\n",
    "base_model.trainable = False\n",
    "\n",
    "# Add custom layers on top\n",
    "inputs = tf.keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "x = base_model(inputs, training=False)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "outputs = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(ds_train, epochs=5, validation_data=ds_test)\n",
    "\n",
    "# Plot training results\n",
    "plt.plot(history.history['accuracy'], label='train_accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fine-Tuning with ResNet50\n",
    "In **fine-tuning**, we unfreeze some layers of the pre-trained model and train them along with the new classifier. This can improve performance but requires careful tuning to avoid overfitting.\n",
    "\n",
    "Here, we'll use ResNet50 and fine-tune the last few layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ResNet50 model (without the top layer)\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "# Freeze all layers initially\n",
    "base_model.trainable = False\n",
    "\n",
    "# Unfreeze the last few layers\n",
    "base_model.trainable = True\n",
    "fine_tune_at = 100  # Unfreeze from this layer onwards\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom layers on top\n",
    "inputs = tf.keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "x = base_model(inputs, training=False)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "outputs = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "# Compile the model with a lower learning rate\n",
    "model.compile(optimizer=Adam(learning_rate=1e-5),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(ds_train, epochs=5, validation_data=ds_test)\n",
    "\n",
    "# Plot training results\n",
    "plt.plot(history.history['accuracy'], label='train_accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Practical Application: Evaluating the Model\n",
    "Let's evaluate the fine-tuned ResNet50 model on the test set and visualize some predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(ds_test)\n",
    "print(f'Test accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "# Visualize predictions\n",
    "def show_predictions(dataset, model):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for images, labels in dataset.take(1):\n",
    "        preds = model.predict(images)\n",
    "        for i in range(9):\n",
    "            plt.subplot(3, 3, i + 1)\n",
    "            plt.imshow(images[i])\n",
    "            pred_label = 'Dog' if preds[i] > 0.5 else 'Cat'\n",
    "            true_label = 'Dog' if labels[i] == 1 else 'Cat'\n",
    "            plt.title(f'Pred: {pred_label}\\nTrue: {true_label}')\n",
    "            plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "show_predictions(ds_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusion\n",
    "In this notebook, we:\n",
    "- Learned how to use pre-trained models (VGG16, ResNet50) for transfer learning.\n",
    "- Implemented **feature extraction** by freezing the base model and training a new classifier.\n",
    "- Performed **fine-tuning** by unfreezing parts of the base model for better performance.\n",
    "- Applied these techniques to classify images in the Cats vs Dogs dataset.\n",
    "\n",
    "### Next Steps:\n",
    "- Experiment with other pre-trained models (e.g., InceptionV3, EfficientNet).\n",
    "- Try transfer learning on your own dataset.\n",
    "- Explore advanced fine-tuning strategies, such as learning rate schedules."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}