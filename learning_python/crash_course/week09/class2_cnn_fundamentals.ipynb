{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class 2: Convolutional Neural Networks Fundamentals\n",
    "\n",
    "**Week 9: Convolutional Neural Networks (CNNs) and Image Processing**\n",
    "\n",
    "## Objective\n",
    "In this class, we'll dive into **Convolutional Neural Networks (CNNs)**, the backbone of deep learning for images. You'll learn how CNNs process image data and build a simple CNN to classify images from the CIFAR-10 dataset.\n",
    "\n",
    "## Agenda\n",
    "1. Why use CNNs for images?\n",
    "2. Understanding CNN layers: convolutions, pooling, and fully connected layers.\n",
    "3. Building a simple CNN with TensorFlow/Keras.\n",
    "4. Exercise: Modify and experiment with the CNN architecture.\n",
    "\n",
    "## Setup\n",
    "Ensure you have the required libraries installed:\n",
    "```bash\n",
    "pip install tensorflow numpy matplotlib\n",
    "```\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Why Use CNNs?\n",
    "\n",
    "Images are high-dimensional (e.g., a 32x32x3 image has 3,072 values). Fully connected neural networks (like MLPs) struggle with images because:\n",
    "- They have too many parameters, leading to overfitting and high computation.\n",
    "- They ignore spatial structure (e.g., nearby pixels form patterns like edges).\n",
    "\n",
    "**Convolutional Neural Networks (CNNs)** solve this by:\n",
    "- Using **filters** to detect local patterns (e.g., edges, textures).\n",
    "- Sharing weights to reduce parameters.\n",
    "- Leveraging spatial hierarchies to learn complex features.\n",
    "\n",
    "Let's explore the key components of a CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: CNN Layers\n",
    "\n",
    "A CNN typically has three main types of layers:\n",
    "\n",
    "1. **Convolutional Layers**:\n",
    "   - Apply **filters** (e.g., 3x3 kernels) to input images to produce **feature maps**.\n",
    "   - Each filter detects a specific pattern (e.g., horizontal edges).\n",
    "   - Parameters: Number of filters, kernel size, stride, padding.\n",
    "   - Example: A 32x32x3 image with 16 3x3 filters produces 16 feature maps.\n",
    "\n",
    "2. **Pooling Layers**:\n",
    "   - Reduce spatial dimensions (e.g., from 32x32 to 16x16) to lower computation and prevent overfitting.\n",
    "   - Common type: **Max pooling** (takes the maximum value in a region, e.g., 2x2).\n",
    "   - Example: 2x2 max pooling with stride 2 halves the width and height.\n",
    "\n",
    "3. **Fully Connected Layers**:\n",
    "   - Flatten feature maps and feed them into dense layers for classification.\n",
    "   - Example: Output layer with 10 neurons for CIFAR-10's 10 classes.\n",
    "\n",
    "4. **Activation Functions**:\n",
    "   - **ReLU** (Rectified Linear Unit) is commonly used after convolutions to add non-linearity (`max(0, x)`).\n",
    "\n",
    "**Question**: Why does pooling help prevent overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Building a Simple CNN\n",
    "\n",
    "We'll use TensorFlow/Keras to build a CNN for CIFAR-10 classification. The architecture will include:\n",
    "- 1 convolutional layer (16 filters, 3x3 kernel, ReLU).\n",
    "- 1 max pooling layer (2x2).\n",
    "- 1 fully connected layer for classification.\n",
    "\n",
    "First, let's load and preprocess the CIFAR-10 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values to [0, 1]\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Define class names\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "# Verify shapes\n",
    "print('Training data shape:', x_train.shape)\n",
    "print('Test data shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation**:\n",
    "- We normalized pixel values (0-255 to 0-1) to help the model train faster.\n",
    "- `x_train`: 50,000 images of shape (32, 32, 3).\n",
    "- `y_train`: Labels as integers (0-9)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's define the CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Build the CNN\n",
    "model = Sequential([\n",
    "    # Convolutional layer: 16 filters, 3x3 kernel, ReLU activation\n",
    "    Conv2D(16, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    # Max pooling: 2x2 pool size\n",
    "    MaxPooling2D((2, 2)),\n",
    "    # Flatten feature maps for dense layer\n",
    "    Flatten(),\n",
    "    # Fully connected layer: 10 outputs for 10 classes\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Display model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation**:\n",
    "- `Conv2D`: Applies 16 3x3 filters, outputs 16 feature maps.\n",
    "- `MaxPooling2D`: Reduces feature maps from 30x30 to 15x15 (after convolution padding).\n",
    "- `Flatten`: Converts feature maps to a 1D vector.\n",
    "- `Dense`: Outputs probabilities for 10 classes (softmax activation).\n",
    "- `sparse_categorical_crossentropy`: Loss function for integer labels.\n",
    "- `model.summary()`: Shows layer shapes and parameter counts.\n",
    "\n",
    "**Question**: How does the number of filters affect the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train the model for a few epochs (this may take a minute)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(x_train, y_train, epochs=5, batch_size=32,\n",
    "                    validation_data=(x_test, y_test))\n",
    "\n",
    "# Plot training accuracy\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation**:\n",
    "- Trained for 5 epochs to keep it quick (accuracy may be low due to simplicity).\n",
    "- Plotted accuracy to visualize learning progress.\n",
    "- Validation accuracy (on test set) shows how well the model generalizes.\n",
    "\n",
    "**Note**: This is a basic model. We'll improve it in later classes!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Visualizing Predictions\n",
    "\n",
    "Let's see how the model performs on a few test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on first 9 test images\n",
    "predictions = model.predict(x_test[:9])\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Display images with predicted and true labels\n",
    "plt.figure(figsize=(8, 8))\n",
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(x_test[i])\n",
    "    plt.title(f'Pred: {class_names[predicted_labels[i]]}\\nTrue: {class_names[y_test[i][0]]}')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation**:\n",
    "- `model.predict`: Outputs probabilities for each class.\n",
    "- `np.argmax`: Selects the class with the highest probability.\n",
    "- Compare predicted vs. true labels to evaluate performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Experiment with the CNN\n",
    "\n",
    "Now it's your turn! Complete the tasks below to explore CNNs further.\n",
    "\n",
    "1. **Modify the Number of Filters**:\n",
    "   - Change the number of filters in the `Conv2D` layer to 32 (instead of 16).\n",
    "   - Rebuild, compile, and check the new model summary.\n",
    "   - How does the number of parameters change?\n",
    "\n",
    "2. **Add Another Convolutional Layer**:\n",
    "   - Add a second `Conv2D` layer with 8 filters (3x3, ReLU) before the pooling layer.\n",
    "   - Rebuild, compile, and train the model for 5 epochs.\n",
    "   - Plot the training and validation accuracy.\n",
    "\n",
    "3. **Challenge (Optional)**:\n",
    "   - Change the kernel size of the first `Conv2D` layer to 5x5 (instead of 3x3).\n",
    "   - Train the model and compare validation accuracy to the original model.\n",
    "   - What might a larger kernel size do?\n",
    "\n",
    "Write your code in the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: Modify number of filters to 32\n",
    "# Your code here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Task 2: Add another convolutional layer\n",
    "# Your code here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Task 3 (Optional): Change kernel size to 5x5\n",
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap-Up\n",
    "\n",
    "In this class, you:\n",
    "- Learned why CNNs are suited for image data.\n",
    "- Understood convolutional, pooling, and fully connected layers.\n",
    "- Built and trained a simple CNN on CIFAR-10.\n",
    "- Visualized predictions and explored model performance.\n",
    "\n",
    "**Homework**:\n",
    "- Experiment with changing the number of filters or kernel size in the CNN and observe effects on the model summary.\n",
    "- Read about image preprocessing (resizing, augmentation) for the next class.\n",
    "- Submit your completed notebook if required.\n",
    "\n",
    "**Next Class**: We'll focus on image preprocessing and training CNNs effectively!\n",
    "\n",
    "Questions? Feel free to ask!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}